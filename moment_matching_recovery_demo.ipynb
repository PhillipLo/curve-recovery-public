{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from jax import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from data_generation import *\n",
    "from moments import *\n",
    "from subspace_recovery import *\n",
    "from projection import *\n",
    "from loss_functions import *\n",
    "from optim import *\n",
    "from tracing_recovery import *\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "seed = 0\n",
    "key, subkey = random.split(random.PRNGKey(seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the data\n",
    "\n",
    "We want to generate a curve with $M$ segments in $\\mathbb{R}^d$ for $d>M$. We generate our curve by prescribing $M$ segment lengths `seg_lens` ahead of time, starting at the origin, and iteratively sampling a direction on the unit sphere to walk in for a distance of `seg_lens[i]`. The segment lengths are chosen uniformly from $[1, 2]$. We center the curve to have mean zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 12 # ambient dimension\n",
    "M = 8 # number of segments\n",
    "sigma2 = 0.25 # noise level\n",
    "\n",
    "seg_lens = random.uniform(subkey, shape = (M,), minval = 0.8, maxval = 1.2) \n",
    "\n",
    "C = gen_curve_sphere_sampling(seed, M, d, seg_lens)\n",
    "C = C - compute_m1(C)\n",
    "\n",
    "chunk_size = int(1e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"real-world\" use case for this problem is to estimate the underlying curve from a high noise point cloud around the data by estimating the moments of the underlying curve from the moments of the point cloud. The moments of the underlying curve can be arbitrarily well-approximated given a sufficiently large number of data points, but the moment approximation is memory-intensive. We can either assume we have access to the true moments of the underlying curves by setting `use_true_moments` to `True`, or estimate the moments by setting it equal to false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_true_moments = False\n",
    "N = int(1e7)\n",
    "N_mini = int(1e4)\n",
    "\n",
    "if use_true_moments:\n",
    "  m1 = compute_m1(C)\n",
    "  m2 = compute_m2(C)\n",
    "  m3 = compute_m3(C)\n",
    "\n",
    "else:\n",
    "  m1_raw, m2_raw, m3_raw, cloud_mini = gen_cloud_moments(subkey, C, sigma2, N, num_chunks = N // chunk_size, N_mini = N_mini)\n",
    "  m1 = m1_raw\n",
    "  m2 = m2_raw - sigma2 * jnp.eye(d)\n",
    "  m3 = m3_raw - 3 * sigma2 * compute_sym_part(jnp.einsum(\"i, jk -> ijk\", m1, jnp.eye(d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial guess with tensor power method\n",
    "\n",
    "We apply the tensor power method to the third moment (whitening with the second moment) to approximate the subspaces in which the control points of $C$ lie. The tensor power method is only able to recover the subspaces up to permutation, so we need to sort them with our chaining algorithm (Algorithm 1 in the paper). A status of zero indicates that the sorting of subspaces was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subspaces, status = recover_C_subspaces(m3, m2, M, seed = 0)\n",
    "print(status)\n",
    "if status != 0:\n",
    "  print(f\"subspace recovery failed with status {status}! results may be suboptimal. see docstring for recover_C_subspaces() for details.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an initial approximation, we now find the lengths of the control points along the estimated subspaces that minimize the moment errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lhat_init = jnp.ones(shape = (M+1,))\n",
    "Chat_subspaces = estimate_C_from_subspaces(subspaces, Lhat_init, m1, m2, m3)\n",
    "print(f\"curve loss: {compute_curve_loss(C, Chat_subspaces):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning with projection and direct moment matching.\n",
    "\n",
    "Before fine-tuning our estimation, we now project the curve to a lower dimensional subspace spanned by top $M$ eigenvectors of the second moment matrix (either of the true curve or the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = get_basis(m2, M)\n",
    "Chat_projected = project_to_subspace(Chat_subspaces.T, basis).T\n",
    "\n",
    "if use_true_moments:\n",
    "  C_projected = project_to_subspace(C.T, basis).T\n",
    "  m1_projected = compute_m1(C_projected)\n",
    "  m2_projected = compute_m2(C_projected)\n",
    "  m3_projected = compute_m3(C_projected)\n",
    "\n",
    "else:\n",
    "  m1_projected, m2_projected, m3_projected = project_moments(m1, m2, m3, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within this subspace, we optimize the curve points themselves (rather than their lengths) to minimize moment losses. If the ground truth curve has uniform lengths, we use the relaxed moments; otherwise, we use the true moments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phat = compute_seg_lens(Chat_projected)\n",
    "phat = phat / jnp.sum(phat)\n",
    "\n",
    "Cp_dict = {\"Chat\" : Chat_projected, \"phat\" : phat}\n",
    "\n",
    "Chat_projected, phat = finetune_C_with_moments(Chat_projected, phat, m3_projected, nit = 2500)\n",
    "Chat = deproject_from_subspace(Chat_projected.T, basis).T\n",
    "\n",
    "print(f\"curve loss: {compute_curve_loss(C, Chat)}\")\n",
    "print(f\"third moment loss: {m3_loss(Chat, m3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute baselines\n",
    "\n",
    "Match either the third moment only or all three moments from a random initialization in the $M$-dimensional subspace that $C$ lives in, taking the best of 10 random initializations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_Chat_m123, best_Chat_m3 = estimate_C_baseline(seed, m1_projected, m2_projected, m3_projected, M, num_trials = 10)\n",
    "Chat_baseline_m123 = deproject_from_subspace(best_Chat_m123.T, basis).T\n",
    "Chat_baseline_m3 = deproject_from_subspace(best_Chat_m3.T, basis).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_loss_m123_baseline = compute_curve_loss(C, Chat_baseline_m123)\n",
    "curve_loss_m3_baseline = compute_curve_loss(C, Chat_baseline_m3)\n",
    "m3_loss_m123_baseline = m3_loss(Chat_baseline_m123, compute_m3(C))\n",
    "m3_loss_m3_baseline = m3_loss(Chat_baseline_m3, compute_m3(C))\n",
    "print(f\"curve loss from triple moment baseline: {curve_loss_m123_baseline:.5f}\")\n",
    "print(f\"curve loss from third moment baseline: {curve_loss_m3_baseline:.5f}\")\n",
    "print(f\"third moment loss from triple moment baseline: {m3_loss_m123_baseline:.5f}\")\n",
    "print(f\"third moment loss from third moment baseline: {m3_loss_m3_baseline:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx0, idx1, idx2 = 0, 1, 2 # choose three random dimensions to project the data down to\n",
    "\n",
    "fig = go.Figure(layout=dict(width=900, height=600))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x = C[:, idx0], y = C[:, idx1], z = C[:, idx2], name = \"C true <br>\", mode = \"lines\", line = dict(color = \"blue\", width = 5)))\n",
    "fig.add_trace(go.Scatter3d(x = Chat_subspaces[:, idx0], y = Chat_subspaces[:, idx1], z = Chat_subspaces[:, idx2], name = \"C predicted <br> after phase 1 <br>\", mode = \"lines\", line = dict(color = \"red\", dash = \"dashdot\", width = 5)))\n",
    "fig.add_trace(go.Scatter3d(x = Chat[:, idx0], y = Chat[:, idx1], z = Chat[:, idx2], name = \"C predicted <br> after phase 2 <br>\", mode = \"lines\", line = dict(color = \"red\", width = 5)))\n",
    "fig.add_trace(go.Scatter3d(x = Chat_baseline_m3[:, idx0], y = Chat_baseline_m3[:, idx1], z = Chat_baseline_m3[:, idx2], name = \"C baseline with third <br> moment matching only<br>\", mode = \"lines\", line = dict(color = \"orange\", dash = \"dot\", width = 3)))\n",
    "fig.add_trace(go.Scatter3d(x = Chat_baseline_m123[:, idx0], y = Chat_baseline_m123[:, idx1], z = Chat_baseline_m123[:, idx2], name = \"C baseline with all <br> three moments<br>\", mode = \"lines\", line = dict(color = \"orange\", width = 3)))\n",
    "if not use_true_moments:\n",
    "  fig.add_trace(go.Scatter3d(x = cloud_mini[:, idx0], y = cloud_mini[:, idx1], z = cloud_mini[:, idx2], hoverinfo=\"skip\", name = \"point cloud\", mode = \"markers\", marker = dict(color = \"blue\", size = 1, opacity = 0.1)))\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curve-recovery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
